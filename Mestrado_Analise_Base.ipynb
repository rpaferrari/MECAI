{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb51cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84406802",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = rf'D:\\OneDrive\\Documentos\\Materiais didáticos\\MECAI\\Dissertação\\script\\Results'\n",
    "name_path = 'results.csv'\n",
    "complete_path = os.path.join(dir_path, name_path)\n",
    "\n",
    "df_res = pd.read_csv(complete_path, encoding='latin-1')\n",
    "df_res = df_res.loc[df_res['Valor'] != 0, :]\n",
    "df_res.loc[:, 'Tempo'] = df_res.loc[:, 'Tempo'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48ed99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = rf'D:\\OneDrive\\Documentos\\Materiais didáticos\\MECAI\\Dissertação\\script\\Dados Gerados Mestrado\\Auxiliar'\n",
    "\n",
    "# df_cluster_cds_cities = pd.read_csv(os.path.join(dir, 'df_cluster_cds_cities.csv'))\n",
    "# df_cluster_pa_cities = pd.read_csv(os.path.join(dir, 'df_cluster_pa_cities.csv'))\n",
    "df_dist_CD_PA = pd.read_csv(os.path.join(dir, 'df_dist_CD_PA.csv'))\n",
    "df_dist_ZD_PA = pd.read_csv(os.path.join(dir, 'df_dist_ZD_PA.csv'))\n",
    "df_instalacao = pd.read_csv(os.path.join(dir, 'df_instalacao.csv'))\n",
    "df_desinstalacao = pd.read_csv(os.path.join(dir, 'df_desinstalacao.csv'))\n",
    "df_dist_Fab_CD = pd.read_csv(os.path.join(dir, 'df_dist_Fab_CD.csv'))\n",
    "df_dist_CD_Desc = pd.read_csv(os.path.join(dir, 'df_dist_CD_Desc.csv'))\n",
    "# df_regiao_pa_zd = pd.read_csv(os.path.join(dir, 'df_regiao_pa_zd.csv'))\n",
    "\n",
    "df_estq_inicial = pd.read_csv(os.path.join(dir, 'df_estq_inicial.csv'))\n",
    "df_estq_inicial = df_estq_inicial.loc[:, ['PA', 'lim_estq_in_pa', 'Restr_Rec', 'Restr_Env']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "262824fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpafe\\AppData\\Local\\Temp\\ipykernel_20136\\2741838635.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[name_col_pivot] = df[name_col_pivot].replace(mapa)\n",
      "C:\\Users\\rpafe\\AppData\\Local\\Temp\\ipykernel_20136\\2741838635.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[name_col_pivot] = df[name_col_pivot].replace(mapa)\n"
     ]
    }
   ],
   "source": [
    "def pivotar_demanda_mensal(df, colunas_valor, name_col, name_col_pivot, mapa=None):\n",
    "    \"\"\"\n",
    "    Função para pivotar o DataFrame de instalação, transformando as colunas de demanda mensal\n",
    "    em uma coluna única com os meses representados por números de 0 a 11.\n",
    "    \n",
    "    Parâmetros:\n",
    "    df_instalacao (DataFrame): DataFrame contendo as colunas de demanda mensal.\n",
    "    \n",
    "    Retorna:\n",
    "    DataFrame: DataFrame pivotado com colunas 'ZD', 'mes' e 'demanda'.\n",
    "    \"\"\"\n",
    " \n",
    "    # Aplicando melt\n",
    "    df = df[[name_col] + colunas_valor].melt(\n",
    "        id_vars=name_col,\n",
    "        value_vars=colunas_valor,\n",
    "        var_name= name_col_pivot,\n",
    "        value_name='demanda'\n",
    "    )\n",
    "\n",
    "    if mapa is not None:\n",
    "        df[name_col_pivot] = df[name_col_pivot].replace(mapa)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Lista com os nomes originais das colunas de demanda mensal\n",
    "colunas_demanda = [\n",
    "    'demanda_normal_Jan', 'demanda_normal_Fev', 'demanda_normal_Mar',\n",
    "    'demanda_normal_Abr', 'demanda_normal_Mai', 'demanda_normal_Jun',\n",
    "    'demanda_normal_Jul', 'demanda_normal_Ago', 'demanda_normal_Set',\n",
    "    'demanda_normal_Out', 'demanda_normal_Nov', 'demanda_normal_Dez'\n",
    "]\n",
    "\n",
    "# Dicionário para mapear os meses para valores de 1 a 12\n",
    "mapa_meses = {\n",
    "    'demanda_normal_Jan': 1, 'demanda_normal_Fev': 2, 'demanda_normal_Mar': 3,\n",
    "    'demanda_normal_Abr': 4, 'demanda_normal_Mai': 5, 'demanda_normal_Jun': 6,\n",
    "    'demanda_normal_Jul': 7, 'demanda_normal_Ago': 8, 'demanda_normal_Set': 9,\n",
    "    'demanda_normal_Out': 10, 'demanda_normal_Nov': 11, 'demanda_normal_Dez': 12\n",
    "}\n",
    "\n",
    "# Substituir nomes dos meses pelos índices numéricos\n",
    "df_inst_pivot = pivotar_demanda_mensal(df_instalacao, colunas_demanda, 'ZD', 'mes', mapa_meses)\n",
    "df_dinst_pivot = pivotar_demanda_mensal(df_desinstalacao, colunas_demanda, 'ZD', 'mes', mapa_meses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6341df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def union_dfs_with_different_columns(list_dfs):\n",
    "    \"\"\"\n",
    "    Realiza a união (concatenação) de quatro DataFrames, cada um com 3 colunas,\n",
    "    mesmo que os nomes das colunas sejam diferentes.\n",
    "\n",
    "    Args:\n",
    "        df1 (pd.DataFrame): O primeiro DataFrame.\n",
    "        df2 (pd.DataFrame): O segundo DataFrame.\n",
    "        df3 (pd.DataFrame): O terceiro DataFrame.\n",
    "        df4 (pd.DataFrame): O quarto DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Um novo DataFrame resultante da união dos quatro DataFrames,\n",
    "                      com as colunas renomeadas para 'coluna_1', 'coluna_2', 'coluna_3'.\n",
    "    \"\"\"\n",
    "    dfs = [list_dfs[i] for i in range(len(list_dfs))]\n",
    "    unified_dfs = []\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        if df.shape[1] != 3:\n",
    "            raise ValueError(f\"DataFrame {i+1} não possui 3 colunas. Possui {df.shape[1]}.\")\n",
    "\n",
    "        # Renomeia as colunas para um padrão comum\n",
    "        df_renamed = df.copy()\n",
    "        df_renamed.columns = ['Origem_Dist', 'Destino_Dist', 'Distancia']\n",
    "        unified_dfs.append(df_renamed)\n",
    "\n",
    "    # Concatena todos os DataFrames renomeados\n",
    "    union_df = pd.concat(unified_dfs, ignore_index=True)\n",
    "\n",
    "    return union_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b701aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_cd_pas = [each for each in df_dist_CD_PA.columns if each[:3] == 'PA_']\n",
    "df_dist_CD_PA_pivot = pivotar_demanda_mensal(df_dist_CD_PA, colunas_cd_pas, 'CD', 'PA')\n",
    "\n",
    "colunas_pas_zd = [each for each in df_dist_ZD_PA.columns if each[:3] == 'PA_']\n",
    "df_dist_ZD_PA_pivot = pivotar_demanda_mensal(df_dist_ZD_PA, colunas_pas_zd, 'ZD', 'PA')\n",
    "\n",
    "colunas_cd_fab = [each for each in df_dist_Fab_CD.columns if each[:3] == 'CD_']\n",
    "df_dist_Fab_CD_pivot = pivotar_demanda_mensal(df_dist_Fab_CD, colunas_cd_fab, 'FAB', 'CD')\n",
    "\n",
    "colunas_cd_desc = [each for each in df_dist_CD_Desc.columns if each[:3] == 'CD_']\n",
    "df_dist_CD_Desc_pivot = pivotar_demanda_mensal(df_dist_CD_Desc, colunas_cd_desc, 'DESC', 'CD')\n",
    "\n",
    "list_dfs = [df_dist_CD_PA_pivot, df_dist_ZD_PA_pivot, df_dist_Fab_CD_pivot, df_dist_CD_Desc_pivot]\n",
    "df_dist = union_dfs_with_different_columns(list_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "871b84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_join(df1, df2, left_col, right_col, prefix, how='left'):\n",
    "    # Descobrir colunas que não são chaves\n",
    "    non_key_cols = [col for col in df2.columns]\n",
    "        \n",
    "    # Fazer o merge normalmente\n",
    "    df = df1.merge(df2, left_on=left_col, right_on=right_col, how=how)\n",
    "\n",
    "    # Renomear colunas do df2 com prefixo\n",
    "    df = df.copy().rename(columns={col: f\"{prefix}{col}\" for col in non_key_cols})\n",
    "    \n",
    "    # Remover a coluna de chave do df2\n",
    "    right_list = [f\"{prefix}{right_col[i]}\" for i in range(len(right_col)) if f\"{prefix}{right_col[i]}\" in df.columns]\n",
    "    df = df.drop(columns=right_list, errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51e0cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = left_join(df_res, df_inst_pivot, ['Destino', 'Tempo'], ['ZD', 'mes'], 'p_inst_')\n",
    "df_res = left_join(df_res, df_dinst_pivot, ['Destino', 'Tempo'], ['ZD', 'mes'], 'p_dinst_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84668541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = left_join(df_res, df_dist, ['Origem', 'Destino'], ['Origem_Dist', 'Destino_Dist'], 'p_')\n",
    "df_res = left_join(df_res, df_dist, ['Origem', 'Destino'], ['Destino_Dist', 'Origem_Dist'], 'p_aux_')\n",
    "df_res['p_Distancia'] = df_res['p_Distancia'].fillna(df_res['p_aux_Distancia'])\n",
    "df_res = df_res.drop(columns=['p_aux_Distancia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "868fc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = left_join(df_res, df_estq_inicial, ['Origem'], ['PA'], 'p_ori_pa_')\n",
    "df_res = left_join(df_res, df_estq_inicial, ['Destino'], ['PA'], 'p_dest_pa_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc6b14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substituir_colunas(df, list_col1, list_col2):\n",
    "    for col1, col2 in zip(list_col1, list_col2):\n",
    "        if col1 in df.columns and col2 in df.columns:\n",
    "            df[col1] = df[col1].fillna(df[col2])\n",
    "            df = df.drop(columns=[col2])\n",
    "    return df\n",
    "\n",
    "df_res = substituir_colunas(df_res, ['p_ori_pa_lim_estq_in_pa', 'p_ori_pa_Restr_Rec', 'p_ori_pa_Restr_Env'], \\\n",
    "        ['p_dest_pa_lim_estq_in_pa', 'p_dest_pa_Restr_Rec', 'p_dest_pa_Restr_Env'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a354e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.read_csv(os.path.join(dir_path, 'df_features.csv'), encoding='latin-1')\n",
    "df_features = pd.read_csv(os.path.join(dir_path, 'df_features.csv'), encoding='latin-1')\n",
    "\n",
    "df_res.loc[(df_res['Abrv Var']=='sf'), \n",
    "           'f_ori_fab_lim_estq'] = df_feat['p_ori_fab_lim_estq'].values[0]\n",
    "df_res.loc[(df_res['Abrv Var'].isin(['qac'])),\n",
    "           'f_fab_rest_env'] = df_feat['p_fab_rest_env'].values[0]\n",
    "df_res.loc[(df_res['Abrv Var'].isin(['qrf'])),\n",
    "           'f_fab_rest_rec'] = df_feat['p_fab_rest_rec'].values[0]\n",
    "\n",
    "df_res.loc[(df_res['Abrv Var'].isin(['sc'])),\n",
    "           'c_ori_cd_lim_estq'] = df_feat['p_ori_cd_lim_estq'].values[0]\n",
    "df_res.loc[(df_res['Abrv Var'].isin(['qrf', 'qap', 'qrd'])),\n",
    "           'c_cd_rest_env'] = df_feat['p_cd_rest_env'].values[0]\n",
    "df_res.loc[(df_res['Abrv Var'].isin(['qrc', 'qac'])),\n",
    "           'c_cd_rest_rec'] = df_feat['p_cd_rest_rec'].values[0]\n",
    "\n",
    "# df_res.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d76c3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código\n",
    "def definir_origem_dest(df_res, ltr, ponto):\n",
    "    list_orig_temp = []\n",
    "    list_dest_temp = []\n",
    "    analise_fabrica = []\n",
    "    for ori, dest in zip(df_res['Origem'], df_res['Destino']):\n",
    "        if isinstance(ori, str) and ori[0] == ltr:\n",
    "            list_orig_temp.append(ori)\n",
    "            list_dest_temp.append(dest)\n",
    "        elif isinstance(dest, str) and dest[0] == ltr:\n",
    "            list_orig_temp.append(dest)\n",
    "            list_dest_temp.append(ori)\n",
    "        else:\n",
    "            list_orig_temp.append(np.nan)\n",
    "            list_dest_temp.append(np.nan)\n",
    "        analise_fabrica.append(ponto)\n",
    "    return [list_orig_temp, list_dest_temp, analise_fabrica]\n",
    "\n",
    "df_res.loc[:, ['Origem_Fabrica', 'Destino_Fabrica', 'Analise_Fabrica']] = list(zip(*definir_origem_dest(df_res, 'F', 'Fabrica')))\n",
    "df_res.loc[:, ['Origem_CD', 'Destino_CD', 'Analise_CD']] = list(zip(*definir_origem_dest(df_res, 'C', 'CD')))\n",
    "df_res.loc[:, ['Origem_PA', 'Destino_PA', 'Analise_PA']] = list(zip(*definir_origem_dest(df_res, 'P', 'PA')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0f8a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma variável para a condição de filtro, evitando repetição\n",
    "filtro_origem = (~df_res['Origem_Fabrica'].isna()) & (df_res['Origem_Fabrica'].str.startswith('F'))\n",
    "\n",
    "# 1. Calcular percentual de restrição de envio\n",
    "df_res.loc[filtro_origem, 'perc_restr_env_fab'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qac'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'f_fab_rest_env']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qac'])), 'agg_fab'] = 'Env_Fab'\n",
    "\n",
    "# 2. Corrigir e calcular percentual de restrição de recebimento\n",
    "# A lista de 'qap' estava redundante e foi simplificada para ['qap']\n",
    "df_res.loc[filtro_origem, 'perc_restr_rec_fab'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qrf'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'f_fab_rest_rec']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qrf'])), 'agg_fab'] = 'Rec_Fab'\n",
    "\n",
    "# 3. Calcular percentual de restrição de estoque\n",
    "df_res.loc[filtro_origem, 'perc_restr_estq_fab'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['sf'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'f_ori_fab_lim_estq']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['sf'])), 'agg_fab'] = 'Estq_Fab'\n",
    "\n",
    "del filtro_origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcfe3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma variável para a condição de filtro, evitando repetição\n",
    "filtro_origem = (~df_res['Origem_CD'].isna()) & (df_res['Origem_CD'].str.startswith('C'))\n",
    "\n",
    "# 1. Calcular percentual de restrição de envio\n",
    "df_res.loc[filtro_origem, 'perc_restr_env_cd'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qap', 'qrd', 'qrf'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'c_cd_rest_env']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qap', 'qrd', 'qrf'])), 'agg_cd'] = 'Env_CD'\n",
    "\n",
    "# 2. Corrigir e calcular percentual de restrição de recebimento\n",
    "# A lista de 'qap' estava redundante e foi simplificada para ['qap']\n",
    "df_res.loc[filtro_origem, 'perc_restr_rec_cd'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qrc', 'qac'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'c_cd_rest_rec']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qrc', 'qac'])), 'agg_cd'] = 'Rec_CD'\n",
    "\n",
    "# 3. Calcular percentual de restrição de estoque\n",
    "df_res.loc[filtro_origem, 'perc_restr_estq_cd'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['sc'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'c_ori_cd_lim_estq']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['sc'])), 'agg_cd'] = 'Estq_CD'\n",
    "\n",
    "del filtro_origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8beda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma variável para a condição de filtro, evitando repetição\n",
    "filtro_origem = (~df_res['Origem_PA'].isna()) & (df_res['Origem_PA'].str.startswith('P'))\n",
    "\n",
    "# 1. Calcular percentual de restrição de envio\n",
    "df_res.loc[filtro_origem, 'perc_restr_env_pa'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qaj', 'qrc'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'p_ori_pa_Restr_Env']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qaj', 'qrc'])), 'agg_pa'] = 'Env_PA'\n",
    "\n",
    "\n",
    "# 2. Corrigir e calcular percentual de restrição de recebimento\n",
    "# A lista de 'qap' estava redundante e foi simplificada para ['qap']\n",
    "df_res.loc[filtro_origem, 'perc_restr_rec_pa'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qap', 'qrp'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'p_ori_pa_Restr_Rec']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['qap', 'qrp'])), 'agg_pa'] = 'Rec_PA'\n",
    "\n",
    "# 3. Calcular percentual de restrição de estoque\n",
    "df_res.loc[filtro_origem, 'perc_restr_estq_pa'] = (\n",
    "    df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['sp'])), 'Valor'] /\n",
    "    df_res.loc[filtro_origem, 'p_ori_pa_lim_estq_in_pa']\n",
    ")\n",
    "df_res.loc[filtro_origem & (df_res['Abrv Var'].isin(['sp'])), 'agg_pa'] = 'Estq_PA'\n",
    "\n",
    "del filtro_origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6c3b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv(os.path.join(dir_path, \"df_res.csv\"), encoding='latin-1', index=False)\n",
    "df_res.to_excel(os.path.join(dir_path, \"df_res.xlsx\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
